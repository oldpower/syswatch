import requests
import json
import time
from multiprocessing import Pool

def unstreamfunc(modelname):
    response = requests.post(
        "http://localhost:11434/api/generate",
        json={
            "model": modelname,
            "prompt": "è§£é‡Šä¸€ä¸‹é‡å­è®¡ç®—.",
            "stream": False
        }
    )
    # print(response.json()["response"])
    timeconsuming(response.json())

def streamfunc(modelname):

    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
    total_tokens = 0          # ç´¯è®¡ç”Ÿæˆçš„ Token æ•°

    response = requests.post(
        "http://localhost:11434/api/chat",
        json={
            "model": modelname,
            "messages": [
                {"role": "user", "content": "ä»‹ç»ä¸€ä¸‹é‡å­è®¡ç®—."},
            ],
            "stream": True
        },
        stream=True
    )

    for line in response.iter_lines():
        if line:
            data = json.loads(line.decode('utf-8'))
            # print(data)
            # print(data.get("message", {}).get("content", ""), end="", flush=True)

            # ç´¯è®¡ Token æ•°é‡ï¼ˆeval_count æ˜¯å½“å‰åˆ†å—çš„ Token æ•°ï¼‰
            if "eval_count" in data:
                total_tokens += data["eval_count"]
                elapsed_time = time.time() - start_time
                current_speed = total_tokens / elapsed_time  # å®æ—¶é€Ÿåº¦
                print(f"[å®æ—¶é€Ÿåº¦: {current_speed:.2f} Tokens/ç§’]", end="\r")  # åŠ¨æ€æ˜¾ç¤º

    # æœ€ç»ˆç»Ÿè®¡
    total_time = time.time() - start_time
    print()
    # print(f"\n\n=== ç”Ÿæˆç»“æŸ ===")
    # print(f"æ€»ç”Ÿæˆ Token æ•°: {total_tokens}")
    # print(f"æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"ç”Ÿæˆå¹³å‡é€Ÿåº¦: {total_tokens / total_time:.2f} Tokens/ç§’")

def timeconsuming(response):
    # æå–å…³é”®å­—æ®µ
    eval_count = response["eval_count"]
    eval_duration_ns = response["eval_duration"]
    prompt_eval_count = response["prompt_eval_count"]
    prompt_duration_ns = response["prompt_eval_duration"]

    # è®¡ç®—é€Ÿåº¦
    gen_speed = eval_count / (eval_duration_ns * 1e-9)
    prompt_speed = prompt_eval_count / (prompt_duration_ns * 1e-9)

    print(f"ğŸ›¸ç”Ÿæˆå¹³å‡é€Ÿåº¦: {gen_speed:.2f} Tokens/ç§’")
    # print(f"Prompt å¤„ç†é€Ÿåº¦: {prompt_speed:.2f} Tokens/ç§’")

# streamfunc()

if __name__ == "__main__":
    modelnames = ["qwen2:0.5b","qwen3:0.6b","qwen3:1.7b"]

    modelname = modelnames[2]
    print(f"ğŸš€modelname is {modelname}")
    # print("ğŸ‘‡éæµ:")
    # unstreamfunc(modelname=modelname)
    # print()
    # print("ğŸ‘‡æµå¼:")
    # streamfunc(modelname=modelname)

    num_processes = 4 
    print(f"num_processes is {num_processes}")
    with Pool(processes=num_processes) as pool:
        # ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹ååˆ›å»ºå‚æ•°åˆ—è¡¨
        pool.map(streamfunc, [modelname]*num_processes)
